{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as opt\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nimport math\n\nfrom tqdm import tqdm, trange\n\n\nfrom torchvision.transforms import ToTensor\nfrom torchvision.datasets.mnist import MNIST\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, image_dim: tuple, patch_dim: tuple, in_channels: int, embed_dim: int):\n        super().__init__()\n        self.embed_dim = embed_dim\n        padding_x = (patch_dim[0] - (image_dim[0] % patch_dim[0])) % patch_dim[0]\n        padding_y = (patch_dim[1] - (image_dim[1] % patch_dim[1])) % patch_dim[1]\n        self.padding = (padding_x, padding_y)\n        self.projection = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_dim, stride=patch_dim, padding=self.padding)\n\n    def forward(self, x):\n        n = x.shape[0]\n        x = self.projection(x)\n        x = x.flatten(start_dim=-2)\n        x = torch.transpose(x, -2, -1)\n        return x\n\n\n\nclass ViT(nn.Module):\n    def __init__(self, image_dim: tuple, device, in_channels=3, n_encoders=1, patch_dim=(16, 16), hidden_dim=512, n_heads=8, out_dim=10):\n        super().__init__()\n        self.image_dim = image_dim\n        self.in_channels = in_channels\n        self.patch_dim = patch_dim\n        self.n_heads = n_heads\n        self.out_dim = out_dim\n        self.device = device\n        self.n_encoders = n_encoders\n        n_patches_x = image_dim[0] // patch_dim[0] if image_dim[0] % patch_dim[0] == 0 else image_dim[0] // patch_dim[0] + 1\n        n_patches_y = image_dim[1] // patch_dim[1] if image_dim[1] % patch_dim[1] == 0 else image_dim[1] // patch_dim[1] + 1\n        self.n_patches = n_patches_x * n_patches_y\n        self.hidden_dim = hidden_dim\n\n        \"\"\"\n        # USE THIS WHEN YOU WANT THE SINE-COSINE POSITION EMBEDDINGS INSTEAD OF THE LEARNED POSITION EMBEDDINGS\n        \n        self.pos_embed = nn.Parameter(self.get_pos_embed(self.n_patches + 1))\n        self.pos_embed.requires_grad = False\n\n        \"\"\"\n        self.pos_embed = nn.Parameter(torch.rand(1, self.n_patches + 1, self.hidden_dim))\n        self.class_token = nn.Parameter(torch.rand((1, self.hidden_dim)))\n        self.encoders = nn.ModuleList([Encoder(self.hidden_dim, self.n_heads) for _ in range(self.n_encoders)])\n        self.encoders = nn.Sequential(*(self.encoders))\n        self.mlp = nn.Linear(self.hidden_dim, self.out_dim)\n        self.patchify = PatchEmbedding(self.image_dim, self.patch_dim, self.in_channels, self.hidden_dim)\n\n    def get_pos_embed(self, n_patches: int):\n        result = torch.empty((n_patches, self.hidden_dim))\n        for i in range(n_patches):\n            for j in range(self.hidden_dim):\n                result[i][j] = math.sin(i / (10000 ** (j / self.hidden_dim))) if j % 2 == 0 else math.cos(i / (10000 ** ((j - 1) / self.hidden_dim)))\n        return result\n    \n    def forward(self, x):\n        n = x.shape[0]\n        patch_embeddings = self.patchify(x)\n        assert patch_embeddings.shape == (n, self.n_patches, self.hidden_dim)\n        embeddings = torch.empty(n, patch_embeddings.shape[1] + 1, self.hidden_dim).to(self.device)\n        for i in range(n):\n            embeddings[i] = torch.cat([patch_embeddings[i], self.class_token])\n            embeddings[i] = embeddings[i] + self.pos_embed\n        features = self.encoders(patch_embeddings)[:, 0]\n        return self.mlp(features)\n        \n        \n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, hidden_dim=512, n_heads=8):\n        super().__init__()\n        assert hidden_dim % n_heads == 0\n        self.hidden_dim = hidden_dim\n        self.n_heads = n_heads\n        self.v_dim = self.hidden_dim // self.n_heads\n        self.Q = nn.ModuleList([nn.Linear(self.hidden_dim, self.v_dim) for _ in range(self.n_heads)])\n        self.K = nn.ModuleList([nn.Linear(self.hidden_dim, self.v_dim) for _ in range(self.n_heads)])\n        self.V = nn.ModuleList([nn.Linear(self.hidden_dim, self.v_dim) for _ in range(self.n_heads)])\n        self.softmax = nn.Softmax(dim=-1)\n        self.mlp = nn.Linear(self.hidden_dim, self.hidden_dim)\n\n    def forward(self, sequences):\n        results = []\n        for sequence in sequences:\n            seq_result = []\n            for head in range(self.n_heads):\n                q = self.Q[head](sequence)\n                k = self.K[head](sequence)\n                v = self.V[head](sequence)\n                scores = self.softmax((q @ k.T) / math.sqrt(self.v_dim))\n                z = scores @ v\n                seq_result.append(z)\n            results.append(seq_result)\n        results = [torch.cat([head_result for head_result in seq_result], dim=-1) for seq_result in results]\n        results = torch.cat([result[None, :] for result in results], dim=0)\n        results = self.mlp(results)\n        return results\n    \n\n\nclass Faster_MultiHeadAttention(nn.Module):\n    def __init__(self, hidden_dim=512, n_heads=8):\n        super().__init__()\n        assert hidden_dim % n_heads == 0\n        self.hidden_dim = hidden_dim\n        self.n_heads = n_heads\n        self.v_dim = self.hidden_dim // self.n_heads\n        self.Q = nn.ModuleList([nn.Linear(self.hidden_dim, self.v_dim) for _ in range(self.n_heads)])\n        self.K = nn.ModuleList([nn.Linear(self.hidden_dim, self.v_dim) for _ in range(self.n_heads)])\n        self.V = nn.ModuleList([nn.Linear(self.hidden_dim, self.v_dim) for _ in range(self.n_heads)])\n        self.softmax = nn.Softmax(dim=-1)\n        self.mlp = nn.Linear(self.hidden_dim, self.hidden_dim)\n\n    def forward(self, sequences):\n        results = []\n        for sequence in sequences:\n            seq_result = []\n            for head in range(self.n_heads):\n                q = self.Q[head](sequence)\n                k = self.K[head](sequence)\n                v = self.V[head](sequence)\n                scores = self.softmax((q @ k.T) / math.sqrt(self.v_dim))\n                z = scores @ v\n                seq_result.append(z)\n            results.append(seq_result)\n        results = [torch.cat([head_result for head_result in seq_result], dim=-1) for seq_result in results]\n        results = torch.cat([result[None, :] for result in results], dim=0)\n        results = self.mlp(results)\n        return results\n    \n\n\nclass Encoder(nn.Module):\n    def __init__(self, hidden_dim=512, n_heads=8):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.n_heads = n_heads\n        self.layer_norm = nn.LayerNorm(self.hidden_dim)\n        self.attention = MultiHeadAttention(self.hidden_dim, self.n_heads)\n        self.mlp = nn.Sequential(\n            nn.Linear(self.hidden_dim, self.hidden_dim),\n            nn.GELU(),\n            nn.Linear(self.hidden_dim, self.hidden_dim)\n        )\n\n    def forward(self, x):\n        x_ = x.clone()\n        x = self.layer_norm(x)\n        x = self.attention(x)\n        x = x + x_\n        x_ = x.clone()\n        x = self.layer_norm(x)\n        x = self.mlp(x)\n        x = x + x_\n        del x_\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:41:45.732799Z","iopub.execute_input":"2023-10-02T19:41:45.733159Z","iopub.status.idle":"2023-10-02T19:41:45.760618Z","shell.execute_reply.started":"2023-10-02T19:41:45.733133Z","shell.execute_reply":"2023-10-02T19:41:45.759759Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"LR = 5e-5\nNUM_EPOCHS = 40\nCONVERGENCE_THRESH = 5\nACC_THRESH = 1","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:41:45.762414Z","iopub.execute_input":"2023-10-02T19:41:45.763335Z","iopub.status.idle":"2023-10-02T19:41:45.772288Z","shell.execute_reply.started":"2023-10-02T19:41:45.763303Z","shell.execute_reply":"2023-10-02T19:41:45.771308Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"const_epochs = 0\nmax_acc = 0\nlast_acc = 0","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:41:45.773549Z","iopub.execute_input":"2023-10-02T19:41:45.774425Z","iopub.status.idle":"2023-10-02T19:41:45.782225Z","shell.execute_reply.started":"2023-10-02T19:41:45.774391Z","shell.execute_reply":"2023-10-02T19:41:45.781291Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    transform = ToTensor()\n    train_set = MNIST(root='./datasets', train=True, download=True, transform=transform)\n    test_set = MNIST(root='./datasets', train=False, download=True, transform=transform)\n    train_loader = DataLoader(train_set, shuffle=True, batch_size=50)\n    test_loader = DataLoader(test_set, shuffle=False, batch_size=50)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"using {device}\")\n    # device = torch.device(\"cpu\")\n    model = ViT((28, 28), device, in_channels=1, n_encoders=3, hidden_dim=512, n_heads=8, patch_dim=(7, 7)).to(device)\n    optimizer = opt.Adam(model.parameters(), lr=LR)\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(NUM_EPOCHS):\n        model.train()\n        total_loss = 0.0\n        correct = 0\n        total = 0\n        # Create a tqdm progress bar for the training batches\n        with tqdm(train_loader, unit=\"batch\") as t_bar:\n            for x, y in t_bar:\n                x, y = x.to(device), y.to(device)\n                outputs = model(x)\n                loss = criterion(outputs, y)\n                loss.backward()\n                optimizer.step()\n                optimizer.zero_grad()\n                total_loss += loss.item()\n                predicted = torch.argmax(outputs, dim=-1)\n                total += y.size(0)\n                correct += (predicted == y).sum().item()\n\n                # Update tqdm progress bar description\n                t_bar.set_description(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n                t_bar.set_postfix(loss=total_loss / (total + 1e-8), accuracy=100 * correct / total)\n        acc = 100.0 * correct / total\n        if acc > max_acc:\n            torch.save(model.state_dict(), f\"./{acc}.pt\")\n        if last_acc - acc > ACC_THRESH:\n            const_epochs = 0\n        else:\n            const_epochs += 1\n        if const_epochs == CONVERGENCE_THRESH:\n            break\n        last_acc = acc\n                \n        # Print epoch-level information\n        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {total_loss / (total + 1e-8):.4f}, Accuracy: {100 * correct / total:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:41:45.784442Z","iopub.execute_input":"2023-10-02T19:41:45.785021Z","iopub.status.idle":"2023-10-02T20:45:29.619314Z","shell.execute_reply.started":"2023-10-02T19:41:45.784982Z","shell.execute_reply":"2023-10-02T20:45:29.618427Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"using cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/40: 100%|██████████| 1200/1200 [12:44<00:00,  1.57batch/s, accuracy=80.7, loss=0.0116]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40 - Loss: 0.0116, Accuracy: 80.68%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/40: 100%|██████████| 1200/1200 [12:39<00:00,  1.58batch/s, accuracy=92.3, loss=0.00486]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/40 - Loss: 0.0049, Accuracy: 92.34%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/40: 100%|██████████| 1200/1200 [12:52<00:00,  1.55batch/s, accuracy=94.7, loss=0.00331]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/40 - Loss: 0.0033, Accuracy: 94.73%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/40: 100%|██████████| 1200/1200 [12:45<00:00,  1.57batch/s, accuracy=96, loss=0.00245] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/40 - Loss: 0.0024, Accuracy: 95.99%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/40: 100%|██████████| 1200/1200 [12:41<00:00,  1.58batch/s, accuracy=97, loss=0.0018]   \n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:50:44.988581Z","iopub.execute_input":"2023-10-02T20:50:44.989581Z","iopub.status.idle":"2023-10-02T20:50:44.995689Z","shell.execute_reply.started":"2023-10-02T20:50:44.989539Z","shell.execute_reply":"2023-10-02T20:50:44.994490Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"ViT(\n  (encoders): Sequential(\n    (0): Encoder(\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (attention): MultiHeadAttention(\n        (Q): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (K): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (V): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (softmax): Softmax(dim=-1)\n        (mlp): Linear(in_features=512, out_features=512, bias=True)\n      )\n      (mlp): Sequential(\n        (0): Linear(in_features=512, out_features=512, bias=True)\n        (1): GELU(approximate='none')\n        (2): Linear(in_features=512, out_features=512, bias=True)\n      )\n    )\n    (1): Encoder(\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (attention): MultiHeadAttention(\n        (Q): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (K): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (V): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (softmax): Softmax(dim=-1)\n        (mlp): Linear(in_features=512, out_features=512, bias=True)\n      )\n      (mlp): Sequential(\n        (0): Linear(in_features=512, out_features=512, bias=True)\n        (1): GELU(approximate='none')\n        (2): Linear(in_features=512, out_features=512, bias=True)\n      )\n    )\n    (2): Encoder(\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (attention): MultiHeadAttention(\n        (Q): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (K): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (V): ModuleList(\n          (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n        )\n        (softmax): Softmax(dim=-1)\n        (mlp): Linear(in_features=512, out_features=512, bias=True)\n      )\n      (mlp): Sequential(\n        (0): Linear(in_features=512, out_features=512, bias=True)\n        (1): GELU(approximate='none')\n        (2): Linear(in_features=512, out_features=512, bias=True)\n      )\n    )\n  )\n  (mlp): Linear(in_features=512, out_features=10, bias=True)\n  (patchify): PatchEmbedding(\n    (projection): Conv2d(1, 512, kernel_size=(7, 7), stride=(7, 7))\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    with tqdm(test_loader, unit=\"batch\") as t_bar:\n        for x, y in t_bar:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            predicted = torch.argmax(outputs, dim=-1)\n            total += y.size(0)\n            correct += (predicted == y).sum().item()\n\n            # Update tqdm progress bar description\n            t_bar.set_description(f\"Testing...\")\n            t_bar.set_postfix(loss=total_loss / (total + 1e-8), accuracy=100 * correct / total)\n    acc = 100.0 * correct / total\n    print(f\"Accuracy: {100.0 * correct / total:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:55:00.174046Z","iopub.execute_input":"2023-10-02T20:55:00.174398Z","iopub.status.idle":"2023-10-02T20:55:38.075060Z","shell.execute_reply.started":"2023-10-02T20:55:00.174371Z","shell.execute_reply":"2023-10-02T20:55:38.074140Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"Testing...: 100%|██████████| 200/200 [00:37<00:00,  5.28batch/s, accuracy=96.6, loss=0.0015] ","output_type":"stream"},{"name":"stdout","text":"Accuracy: 96.56%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}