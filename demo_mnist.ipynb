{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T20:14:29.499972Z","iopub.status.busy":"2023-10-03T20:14:29.499607Z","iopub.status.idle":"2023-10-03T20:14:29.528941Z","shell.execute_reply":"2023-10-03T20:14:29.527716Z","shell.execute_reply.started":"2023-10-03T20:14:29.499943Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as opt\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import ToTensor\n","import math\n","\n","from tqdm import tqdm, trange\n","\n","\n","from torchvision.transforms import ToTensor\n","from torchvision.datasets.mnist import MNIST\n","\n","from ViT import ViT"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T20:14:30.080746Z","iopub.status.busy":"2023-10-03T20:14:30.080018Z","iopub.status.idle":"2023-10-03T20:14:30.085561Z","shell.execute_reply":"2023-10-03T20:14:30.084642Z","shell.execute_reply.started":"2023-10-03T20:14:30.080714Z"},"trusted":true},"outputs":[],"source":["LR = 5e-5\n","NUM_EPOCHS = 40\n","CONVERGENCE_THRESH = 5\n","ACC_THRESH = 1"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T20:14:30.634628Z","iopub.status.busy":"2023-10-03T20:14:30.633944Z","iopub.status.idle":"2023-10-03T20:14:30.639128Z","shell.execute_reply":"2023-10-03T20:14:30.638080Z","shell.execute_reply.started":"2023-10-03T20:14:30.634581Z"},"trusted":true},"outputs":[],"source":["const_epochs = 0\n","max_acc = 0\n","last_acc = 0"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T20:14:31.212295Z","iopub.status.busy":"2023-10-03T20:14:31.211603Z","iopub.status.idle":"2023-10-03T20:16:47.126671Z","shell.execute_reply":"2023-10-03T20:16:47.125650Z","shell.execute_reply.started":"2023-10-03T20:14:31.212250Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["using cuda\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/40: 100%|██████████| 1200/1200 [00:28<00:00, 42.26batch/s, accuracy=91, loss=0.00577]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/40 - Loss: 0.0058, Accuracy: 91.00%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/40:  10%|▉         | 118/1200 [00:02<00:24, 44.57batch/s, accuracy=96.9, loss=0.002]  \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, y)\n\u001b[1;32m     24\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 25\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n","File \u001b[0;32m~/anaconda3/envs/gla/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/gla/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n","File \u001b[0;32m~/anaconda3/envs/gla/lib/python3.11/site-packages/torch/optim/adam.py:132\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    129\u001b[0m     state_steps \u001b[39m=\u001b[39m []\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m    135\u001b[0m         grads,\n\u001b[1;32m    136\u001b[0m         exp_avgs,\n\u001b[1;32m    137\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[1;32m    141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfound_inf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/anaconda3/envs/gla/lib/python3.11/site-packages/torch/optim/adam.py:83\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAdam does not support sparse gradients, please consider SparseAdam instead\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m grads\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mgrad)\n\u001b[0;32m---> 83\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate[p]\n\u001b[1;32m     84\u001b[0m \u001b[39m# Lazy state initialization\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(state) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/anaconda3/envs/gla/lib/python3.11/site-packages/torch/_tensor.py:942\u001b[0m, in \u001b[0;36mTensor.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    932\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPassing a tensor of different shape won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt change the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    939\u001b[0m         )\n\u001b[1;32m    940\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munbind(\u001b[39m0\u001b[39m))\n\u001b[0;32m--> 942\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    943\u001b[0m     \u001b[39m# Do NOT handle __torch_function__ here as user's default\u001b[39;00m\n\u001b[1;32m    944\u001b[0m     \u001b[39m# implementation that handle most functions will most likely do it wrong.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m     \u001b[39m# It can be easily overridden by defining this method on the user\u001b[39;00m\n\u001b[1;32m    946\u001b[0m     \u001b[39m# subclass if needed.\u001b[39;00m\n\u001b[1;32m    947\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[1;32m    949\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__dir__\u001b[39m(\u001b[39mself\u001b[39m):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == \"__main__\":\n","    transform = ToTensor()\n","    train_set = MNIST(root='./datasets', train=True, download=True, transform=transform)\n","    test_set = MNIST(root='./datasets', train=False, download=True, transform=transform)\n","    train_loader = DataLoader(train_set, shuffle=True, batch_size=50)\n","    test_loader = DataLoader(test_set, shuffle=False, batch_size=50)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"using {device}\")\n","    # device = torch.device(\"cpu\")\n","    model = ViT((28, 28), device, in_channels=1, n_encoders=3, hidden_dim=512, n_heads=8, patch_dim=(7, 7)).to(device)\n","    optimizer = opt.Adam(model.parameters(), lr=LR)\n","    criterion = nn.CrossEntropyLoss()\n","    for epoch in range(NUM_EPOCHS):\n","        model.train()\n","        total_loss = 0.0\n","        correct = 0\n","        total = 0\n","        # Create a tqdm progress bar for the training batches\n","        with tqdm(train_loader, unit=\"batch\") as t_bar:\n","            for x, y in t_bar:\n","                x, y = x.to(device), y.to(device)\n","                outputs = model(x)\n","                loss = criterion(outputs, y)\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                total_loss += loss.item()\n","                predicted = torch.argmax(outputs, dim=-1)\n","                total += y.size(0)\n","                correct += (predicted == y).sum().item()\n","\n","                # Update tqdm progress bar description\n","                t_bar.set_description(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n","                t_bar.set_postfix(loss=total_loss / (total + 1e-8), accuracy=100 * correct / total)\n","        acc = 100.0 * correct / total\n","        if acc > max_acc:\n","            torch.save(model.state_dict(), f\"./{acc}.pt\")\n","        if last_acc - acc > ACC_THRESH:\n","            const_epochs = 0\n","        else:\n","            const_epochs += 1\n","        if const_epochs == CONVERGENCE_THRESH:\n","            break\n","        last_acc = acc\n","                \n","        # Print epoch-level information\n","        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {total_loss / (total + 1e-8):.4f}, Accuracy: {100 * correct / total:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T20:16:57.715666Z","iopub.status.busy":"2023-10-03T20:16:57.715127Z","iopub.status.idle":"2023-10-03T20:16:57.720511Z","shell.execute_reply":"2023-10-03T20:16:57.719634Z","shell.execute_reply.started":"2023-10-03T20:16:57.715634Z"},"trusted":true},"outputs":[],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T20:17:09.977179Z","iopub.status.busy":"2023-10-03T20:17:09.976861Z","iopub.status.idle":"2023-10-03T20:17:12.725485Z","shell.execute_reply":"2023-10-03T20:17:12.724595Z","shell.execute_reply.started":"2023-10-03T20:17:09.977152Z"},"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    with tqdm(test_loader, unit=\"batch\") as t_bar:\n","        for x, y in t_bar:\n","            x, y = x.to(device), y.to(device)\n","            outputs = model(x)\n","            predicted = torch.argmax(outputs, dim=-1)\n","            total += y.size(0)\n","            correct += (predicted == y).sum().item()\n","\n","            # Update tqdm progress bar description\n","            t_bar.set_description(f\"Testing...\")\n","            t_bar.set_postfix(loss=total_loss / (total + 1e-8), accuracy=100 * correct / total)\n","    acc = 100.0 * correct / total\n","    print(f\"Accuracy: {100.0 * correct / total:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
